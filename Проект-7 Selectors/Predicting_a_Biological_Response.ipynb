{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=molecule.png width=800px height=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # <center> <strong> Kaggle: Predicting a Biological Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вводные данные\n",
    "Наша практика будет основана на соревновании Kaggle: Predicting a Biological Response (Прогнозирование биологического ответа). Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776).\n",
    "\n",
    "Данные представлены в формате CSV. Каждая строка представляет молекулу.\n",
    "\n",
    "* Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1];\n",
    "* Остальные столбцы D1-D1776 представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.\n",
    "Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n",
    "\n",
    "В качестве метрики будем использовать F1-score.\n",
    "\n",
    "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций не должно превышать 50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем все необходимые библиотеки для дальнейшей работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from sklearn import model_selection\n",
    "import optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем датасет в переменную data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"Python 3.12.3\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"/bin/python3 -m pip install ipykernel -U --user --force-reinstall\""
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('_train_sem09__1_.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран 5 строк из нашего датасета, что бы посмотреть из чего состоит он"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задаче указано, что данные подготовленные, но для уверенности смотрим нет ли  пропусков в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записываем в переменные X и y нашу матрицу наблюдений и целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['Activity'],axis=1)\n",
    "y=data['Activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тренировочные и тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом не будем стратифицировать их, т.к. далее мы будем использовать это при оценке нашей модели. Рассмотрим распределение в целевом признаке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные почти одинаково распределены. И миноритальный класс в обоих выборках распределен почти идентично"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  Подбор лучших гиперпараметров с помощью GridSearch для модели LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем наши переменные для дальнейшей работы, KFOLD стратификацию и параметры для поиска лучших из них, отдельно для LogisticRegression и для RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs=StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr=[{'penalty':['l1','l2'],\n",
    "        'solver':['liblinear','saga'],\n",
    "        'C':list(np.arange(0,1.1,0.25))},\n",
    "        {'penalty':['l2',None],\n",
    "        'solver':['lbfgs','sag'],\n",
    "        'C':list(np.arange(0,1.1,0.25))}]\n",
    "params_rf={'n_estimators':list(range(100,401,100)),\n",
    "        'criterion':['entropy','gini'],\n",
    "        'max_depth':[3,5,7],\n",
    "        'min_samples_leaf':[3,5,7]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим нашу функцию GridSearch и выясним, какое время занимает поиск лучших параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logic_GSCV=LogisticRegression(random_state=42,max_iter=200)\n",
    "GridSearch_lr=GridSearchCV(estimator=model_logic_GSCV,\n",
    "             param_grid=params_lr,\n",
    "             n_jobs=-1,\n",
    "             scoring='f1',\n",
    "             cv=cvs)\n",
    "%time GridSearch_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция, путем перебора всех вариантов, которые мы ей предложили справилась за 7 минут 19 секунд"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее выведем на экран лучшие параметры, которая функция предложила и подставим их в модель LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Параметры, полученные с помощью GridSearch для логистической регрессии')\n",
    "print()\n",
    "print('Лучшие параметры:{}'.format(GridSearch_lr.best_params_))\n",
    "print('f1-score для валидационной выборки: {}'.format(GridSearch_lr.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=GridSearch_lr.best_params_['C']\n",
    "penalty=GridSearch_lr.best_params_['penalty']\n",
    "solver=GridSearch_lr.best_params_['solver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logic=LogisticRegression(C=C,penalty=penalty,solver=solver,random_state=42,max_iter=200)\n",
    "model_logic.fit(X_train,y_train)\n",
    "predict_logic_y_train=model_logic.predict(X_train)\n",
    "predict_logic_y_test=model_logic.predict(X_test)\n",
    "print('Результат, полученный подбором гиперпараметров для логистической регрессии, с помощью GridSearch')\n",
    "print()\n",
    "print('Метрика F1-score на тренировочных данных равна:{}'.format((metrics.f1_score(y_train,predict_logic_y_train)).round(3)))\n",
    "print('Метрика F1-score на тестовых данных равна:{}'.format(metrics.f1_score(y_test,predict_logic_y_test).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем в дальнейшем сравивать время обучения функций поиска гиперпараметров между собой,сами гиперпараметры и результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Подбор лучших гиперпараметров с помощью GridSearch для модели RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проделаем тоже самое для модели RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Random_Forest_GSCV=RandomForestClassifier(random_state=42)\n",
    "\n",
    "GridSearch_rf=GridSearchCV(estimator=model_Random_Forest_GSCV,\n",
    "             param_grid=params_rf,\n",
    "             n_jobs=-1,\n",
    "             scoring='f1',\n",
    "             cv=cvs\n",
    ")\n",
    "\n",
    "%time GridSearch_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 минуты 21 секунда, нашей функции GridSearch понадобилось, что бы справится с поиском лучших гиперпараметров для модели RandomForest.Выводим лучший вариант и подставляем их в модель, далее смотрим метрику f1 уже с подобранными гиперпараметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Параметры, полученные с помощью GridSearch для случайного леса')\n",
    "print()\n",
    "print('Лучшие параметры для случайного леса:{}'.format(GridSearch_rf.best_params_))\n",
    "print('f-score для валидационной выборки: {}'.format(GridSearch_rf.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=GridSearch_rf.best_params_['criterion']\n",
    "max_depth=GridSearch_rf.best_params_['max_depth']\n",
    "min_samples_leaf=GridSearch_rf.best_params_['min_samples_leaf']\n",
    "n_estimators=GridSearch_rf.best_params_['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Random_Forest=RandomForestClassifier(criterion=criterion,max_depth=max_depth,min_samples_leaf=min_samples_leaf,n_estimators=n_estimators,random_state=42)\n",
    "\n",
    "model_Random_Forest.fit(X_train,y_train)\n",
    "\n",
    "predict_RF_y_train=model_Random_Forest.predict(X_train)\n",
    "predict_RF_y_test=model_Random_Forest.predict(X_test)\n",
    "\n",
    "print('Результат, полученный подбором гиперпараметров для случайного леса, с помощью GridSearch')\n",
    "print()\n",
    "print('Метрика F1-score на тренировочных данных равна:{}'.format((metrics.f1_score(y_train,predict_RF_y_train)).round(3)))\n",
    "print('Метрика F1-score на тестовых данных равна:{}'.format(metrics.f1_score(y_test,predict_RF_y_test).round(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель более точно предсказала целевой признак на тестовых данных(0.802 против 0.789), но эта разница не значительная. Но все же есть. И в два раза быстрее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Подбор лучших гиперпараметров с помощью RandomizeSearch для LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же, используя все теже самые гиперпараметры будем искать лучшие с помощью функции поиска RandomizeSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logic_RSCV=LogisticRegression(random_state=42,max_iter=200)\n",
    "RandomizedSearch_lr=RandomizedSearchCV(estimator=model_logic_RSCV,\n",
    "                                       param_distributions=params_lr,\n",
    "                                       scoring='f1',\n",
    "                                       n_jobs=-1,\n",
    "                                       n_iter=10)\n",
    "%time RandomizedSearch_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель справляется с задачей за 3 минуты 2 секунды. Что намного быстрее чем модель, которую мы использовали ранее. Выводим на экран результат, далее подставляем их в нашу модель LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Параметры, полученные с помощью RandomizeSearch для логистической регрессии')\n",
    "print()\n",
    "print('Лучшие параметры для логистической регрессии:{}'.format(RandomizedSearch_lr.best_params_))\n",
    "print('f-score для валидационной выборки: {}'.format(RandomizedSearch_lr.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но данная модель посчитала, что лучше будет использовать гиперпараметр solver ни 'liblinear', а  'saga'. Хотя если верить рекомендациям использования данного параметра 'liblinear' данный выбор хорош для небольших датасетов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=RandomizedSearch_lr.best_params_['C']\n",
    "penalty=RandomizedSearch_lr.best_params_['penalty']\n",
    "solver=RandomizedSearch_lr.best_params_['solver']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подставим наши гиперпараметры в модель и посмотрим метрику на тестовых данных.Сравним, смогли ли мы засчет скорости не потерять качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logic=LogisticRegression(C=C,penalty=penalty,solver=solver,random_state=42,max_iter=200)\n",
    "model_logic.fit(X_train,y_train)\n",
    "predict_logic_y_train=model_logic.predict(X_train)\n",
    "predict_logic_y_test=model_logic.predict(X_test)\n",
    "print('Результат, полученный подбором гиперпараметров для логистической регрессии, с помощью RandomizeSearch')\n",
    "print()\n",
    "print('Метрика F1-score на тренировочных данных равна:{}'.format((metrics.f1_score(y_train,predict_logic_y_train)).round(3)))\n",
    "print('Метрика F1-score на тестовых данных равна:{}'.format(metrics.f1_score(y_test,predict_logic_y_test).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что при уменьшении времени в два раза мы не потеряли качество модели, а даже ее улучшили немного. Тем самым модель чуть лучше нашала предугадывать класс."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Подбор лучших гиперпараметров с помощью RandomizeSearch для RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, так же это работает при использовании модели RandomForest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Random_Forest_RSCV=RandomForestClassifier(random_state=42)\n",
    "\n",
    "RandomizedSearch_rf=RandomizedSearchCV(estimator=model_Random_Forest_RSCV,\n",
    "             param_distributions=params_rf,\n",
    "             n_jobs=-1,\n",
    "             scoring='f1',\n",
    "             cv=cvs\n",
    ")\n",
    "\n",
    "%time RandomizedSearch_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель справилась за секунды(36), что почти в три раза быстрее чем модель, которая перебирает все варианты гиперпараметов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Параметры, полученные с помощью RandomizeSearch для случайного леса')\n",
    "print()\n",
    "print('Лучшие параметры для случайного леса:{}'.format(RandomizedSearch_rf.best_params_))\n",
    "print('f-score для валидационной выборки: {}'.format(RandomizedSearch_rf.best_score_.round(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=RandomizedSearch_rf.best_params_['criterion']\n",
    "max_depth=RandomizedSearch_rf.best_params_['max_depth']\n",
    "min_samples_leaf=RandomizedSearch_rf.best_params_['min_samples_leaf']\n",
    "n_estimators=RandomizedSearch_rf.best_params_['n_estimators']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подставим наши данные в модель и узнаем результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Random_Forest=RandomForestClassifier(criterion=criterion,max_depth=max_depth,min_samples_leaf=min_samples_leaf,n_estimators=n_estimators,random_state=42)\n",
    "\n",
    "model_Random_Forest.fit(X_train,y_train)\n",
    "\n",
    "predict_RF_y_train=model_Random_Forest.predict(X_train)\n",
    "predict_RF_y_test=model_Random_Forest.predict(X_test)\n",
    "\n",
    "print('Результат, полученный подбором гиперпараметров для случайного леса, с помощью RandomizeSearch')\n",
    "print()\n",
    "print('Метрика F1-score на тренировочных данных равна:{}'.format((metrics.f1_score(y_train,predict_RF_y_train)).round(3)))\n",
    "print('Метрика F1-score на тестовых данных равна:{}'.format(metrics.f1_score(y_test,predict_RF_y_test).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель поиска гиперпараметров переплюнула результат, который был ранее, не особо много, но время обучения поиска гиперпараметров зато при этом мы снизили почти в три раза, что не может не радовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Подбор лучших гиперпараметров с помощью Tree-Structured Parzen Estimators (TPE) для LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак дошли до более сложных моделей подбора гиперпараметров. Для начало нам надо задать словарь всех вариантов наших гиперпараметров для модели и написать функцию, которая будет возвращать метрику, но т.к. данная функция поиска гиперпараметров основана на минимизации, то нам надо поставить знак минус перед метрикой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr_TPE={'penalty':hp.choice('penalty',['l1','l2']),\n",
    "            'solver':hp.choice(label='solver',options=['liblinear','saga']),\n",
    "            'C':hp.uniform('C',0,1)}\n",
    "\n",
    "\n",
    "def hyperopt_rf(params=params_lr_TPE, cv=5, X=X_train, y=y_train, random_state=42):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty':str(params['penalty']), \n",
    "              'solver': str(params['solver']), \n",
    "             'C': float(params['C'])}\n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = LogisticRegression(**params, random_state=42,max_iter=200)\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И применим нашу написанную функцию в качестве гиперпараметра уже функции минимизации. Так же будем записывать наши результаты в переменную trials, что бы в дальнейшем программа запоминала лучшие результаты, когда мы будем подставлять уже другие гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials() # используется для логирования результатов\n",
    "%time\n",
    "best=fmin(hyperopt_rf, # наша функция FMIN\n",
    "    space=params_lr_TPE, # пространство гиперпараметров\n",
    "    algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно TPE\n",
    "    max_evals=20, # максимальное количество итераций\n",
    "    trials=trials, # логирование результатов   TRIALS\n",
    "    rstate=np.random.default_rng(42)# фиксируем для повторяемости результата\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый долгий по времени алгоритм обучения и поиска лучших гиперпараметров 14 минут 8 секунд. На первый взгляд это самый не интересный алгоритм, но суть его в дальнейшем использовании. Т.к. он запоминает наилучшие варианты и все комбинации, которые были ранее. ПРИ ЭТОМ ОБЯЗАТЕЛЬНО ИСПОЛЬЗОВАТЬ ГИПЕРПАРАМЕТР TRIALS ТОТ ЖЕ, ЧТО И РАНЕЕ ДЛЯ ЭТОЙ МОДЕЛИ, ЧТО БЫ МОДЕЛЬ НАЧАЛА ИСКАТЬ ВАРИАНТ УЖЕ С НОВЫМИ ДАННЫЕ, НО ПОМНИВ ЛУЧШИЙ РЕЗУЛЬТАТ, КОТОРЫЙ БЫЛ ДОСТИГНУТ РАНЕЕ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Параметры, полученные с помощью HYPEROPT для Логистической регрессии')\n",
    "print()\n",
    "print('Лучшие параметры для логистической регрессии:{}'.format(best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге мы получили 'C': 0.4805571687112412, 'penalty': 'l1', 'solver': 'saga'. Подставим эти гиперпараметры в нашу модель LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logic=LogisticRegression(C=best['C'],penalty='l1',solver='saga',random_state=42,max_iter=200)\n",
    "model_logic.fit(X_train,y_train)\n",
    "predict_logic_y_train=model_logic.predict(X_train)\n",
    "predict_logic_y_test=model_logic.predict(X_test)\n",
    "print('Результат, полученный подбором гиперпараметров для логистической регрессии, с помощью HyperOpt')\n",
    "print()\n",
    "print('Метрика F1-score на тренировочных данных равна:{}'.format((metrics.f1_score(y_train,predict_logic_y_train)).round(3)))\n",
    "print('Метрика F1-score на тестовых данных равна:{}'.format(metrics.f1_score(y_test,predict_logic_y_test).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как результат мы видим, что он уступил модели RandomizeGrid, но там мы использовали еще один вариант гиперпараметров и сейчас мы его добавим в наши поиски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lr_TPE_2={'penalty':hp.choice('penalty','l2'),\n",
    "            'solver':hp.choice(label='solver',options=['lbfgs','sag']),\n",
    "            'C':hp.uniform('C',0,1)}\n",
    "\n",
    "\n",
    "def hyperopt_rf(params=params_lr_TPE_2, cv=5, X=X_train, y=y_train, random_state=42):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty':str(params['penalty']), \n",
    "              'solver': str(params['solver']), \n",
    "             'C': float(params['C'])}\n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = LogisticRegression(**params, random_state=42,max_iter=200)\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавили новые сочитания и запускаем поиск. При этом параметр Trials мы оставляем тем же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best=fmin(hyperopt_rf, # наша функция FMIN\n",
    "          space=params_lr_TPE, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно TPE\n",
    "          max_evals=40, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов   TRIALS\n",
    "          rstate=np.random.default_rng(42)# фиксируем для повторяемости результата\n",
    ")          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И после добавления новых данных модель уже справилась с подбором и сравнением лучших комбинаций гиперпараметров за 9 секунд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Параметры, полученные с помощью HYPEROPT для Логистической регрессии')\n",
    "print()\n",
    "print('Лучшие параметры для логистической регрессии:{}'.format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logic=LogisticRegression(C=best['C'],penalty='l2',solver='lbfgs',max_iter=200,random_state=42)\n",
    "model_logic.fit(X_train,y_train)\n",
    "predict_logic_y_train=model_logic.predict(X_train)\n",
    "predict_logic_y_test=model_logic.predict(X_test)\n",
    "print('Результат, полученный подбором гиперпараметров для логистической регрессии, с помощью HyperOpt')\n",
    "print()\n",
    "print('Метрика F1-score на тренировочных данных равна:{}'.format((metrics.f1_score(y_train,predict_logic_y_train)).round(3)))\n",
    "print('Метрика F1-score на тестовых данных равна:{}'.format(metrics.f1_score(y_test,predict_logic_y_test).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В итоге мы получили метрику, примерно одинаковую со всеми моделями, которые были использованы ранее, но за более короткое время, если мы будем не однократно искать нужные параметры, а подбирать все разные и разные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Подбор лучших гиперпараметров с помощью Tree-Structured Parzen Estimators (TPE) для RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же все гиперпараметры и варианты их значений выводим в отдельную переменную и используя функцию возвращаем метрику со знаком минус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf_TPE={'n_estimators':hp.quniform('n_estimators',100,400,100),\n",
    "            'criterion':hp.choice(label='criterion',options=['entropy','gini']),\n",
    "            'max_depth':hp.quniform('max_depth',3,7,2),\n",
    "            'min_samples_leaf':hp.quniform('min_samples_leaf',3,7,2)}\n",
    "             \n",
    "\n",
    "def hyperopt_rf(params=params_lr_TPE, cv=5, X=X_train, y=y_train, random_state=42):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators':int(params['n_estimators']), \n",
    "              'criterion': str(params['criterion']), \n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_samples_leaf': int(params['min_samples_leaf'])}\n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот если у нас поменялась модель, то уже старый trials мы уже не можем использовать, только новый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_rf = Trials() # используется для логирования результатов\n",
    "\n",
    "best_rf=fmin(hyperopt_rf, # наша функция FMIN\n",
    "          space=params_rf_TPE, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно TPE\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials_rf, # логирование результатов   TRIALS\n",
    "          rstate=np.random.default_rng(42)# фиксируем для повторяемости результата\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель справилась за 1 минуту 55 секунд, меньше чем через GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Параметры, полученные с помощью HYPEROPT для Логистической регрессии')\n",
    "print()\n",
    "print('Лучшие параметры для логистической регрессии:{}'.format(best_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Random_Forest=RandomForestClassifier(criterion='entropy',max_depth=6,min_samples_leaf=4,n_estimators=200,random_state=42)\n",
    "model_Random_Forest.fit(X_train,y_train)\n",
    "predict_Random_y_train=model_Random_Forest.predict(X_train)\n",
    "predict_Random_y_test=model_Random_Forest.predict(X_test)\n",
    "print('Результат, полученный подбором гиперпараметров для логистической регрессии, с помощью HyperOpt')\n",
    "print()\n",
    "print('Метрика F1-score на тренировочных данных равна:{}'.format((metrics.f1_score(y_train,predict_Random_y_train)).round(3)))\n",
    "print('Метрика F1-score на тестовых данных равна:{}'.format(metrics.f1_score(y_test,predict_Random_y_test).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получились значения примерно одинаковые, как и получали ранее.Но можно рассмотреть еще другие варианты. Что мы делали ранее. Но лучше мы посмотрим на график, который показывает, как менялась метрика на протяжении всей работы модели по оптимизации гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отрисуем, как менялась точность при различных гиперпараметрах\n",
    "tpe_results=np.array([[x['result']['loss'],\n",
    "                      x['misc']['vals']['criterion'][0],\n",
    "                      x['misc']['vals']['max_depth'][0],\n",
    "                      x['misc']['vals']['n_estimators'][0],\n",
    "                      x['misc']['vals']['min_samples_leaf'][0]] for x in trials_rf.trials])\n",
    "\n",
    "tpe_results_df=pd.DataFrame(tpe_results,\n",
    "                           columns=['score', 'criterion', 'max_depth','n_estimators','min_samples_leaf'])\n",
    "# тепловая карта в данном случае не очень наглядна, возьмем линейный график\n",
    "tpe_results_df.plot(subplots=True,figsize=(10, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике отчетливо видно, что минимальное значение метрики находится чуть дальше отметки 2.5 по оси X. Если провести мысленно вертикальную черту, то на ней окажутся значения следующие:\n",
    "criterion='entropy',\n",
    "max_depth=6,\n",
    "n_estimators=200,\n",
    "min_samples_leaf=4\n",
    "Что и выдала программа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Подбор лучших гиперпараметров с помощью OPTUNA для LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_lg(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  penalty = trial.suggest_categorical('penalty', ['l1','l2'])\n",
    "  solver = trial.suggest_categorical('solver', ['liblinear','saga'])\n",
    "  C= trial.suggest_float('C', low=0,high=1)\n",
    "  # создаем модель\n",
    "  model = LogisticRegression(penalty=penalty,\n",
    "                            solver=solver,\n",
    "                            C=C,\n",
    "                            max_iter=200,\n",
    "                            random_state=42)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_lr = optuna.create_study(study_name=\"LinearRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_lr.optimize(optuna_lg, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И так время обучения модели по оптимизации равно 3 минуты 8 секунд. Достаточно неплоха, по сравнению Hyperopt, посмотрим на качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На обучающей выборке модель показала высокий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(study_lr.best_params) # Наилучшие значения гиперпараметров \n",
    "print(study_lr.best_value) #\"f1_score на обучающем наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = LogisticRegression(**study_lr.best_params,random_state=42,max_iter=200 )\n",
    "model.fit(X_train, y_train)\n",
    "print(\"accuracy на тестовом наборе: {:.3f}\".format(model.score(X_test,y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат действительно у всех моделей более менее схож. Вопрос только в том, как дальше будут использоваться данные модели, либо вариации добавляться либо разово."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем график, где мы увидим, растет ли наша метрика с увеличением итераций.Для начало проверим, можем ли мы воспользоваться данным инструменом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все отлично, визуализируем зависимость метрики от количества итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_lr, target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=Optuna_lr.png width=1450px height=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что наша метрика на тренировочных данных действительно растет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим важность гиперпараметов и посмотрим так же в каких значениях метрика максимальная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study_lr, target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=param_importances_Optuna_lr.png width=1450px height=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым важным параметром оказался C.Это штраф за переобучение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study_lr, params=[\"C\", \"penalty\"],\n",
    "                                  target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=contour_Optuna_lr.png width=1450px height=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот значения самих параметров С чуть меньше 0.2, ранее в моделях наблюдалось повышение данного параметра, тут видим наоборот и penalty l1. Примерно такие же данные показала программа оптимизации HyperOpt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Подбор лучших гиперпараметров с помощью OPTUNA для RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def optuna_rf(trial):\n",
    "    n_estimators=trial.suggest_int('n_estimators',low=100,high=400)\n",
    "    criterion=trial.suggest_categorical('criterion', ['entropy','gini'])\n",
    "    max_depth=trial.suggest_int('max_depth',low=3,high=10)\n",
    "    min_samples_leaf=trial.suggest_int('min_samples_leaf',low=3,high=10)\n",
    "\n",
    "    model_R=RandomForestClassifier(n_estimators=n_estimators,  \n",
    "                                               criterion=criterion,\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_samples_leaf=min_samples_leaf,\n",
    "                                               random_state=42)\n",
    "    model_R.fit(X_train,y_train)\n",
    "    predict_X=model_R.predict(X_train)\n",
    "    score=metrics.f1_score(y_train,predict_X)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "%time\n",
    "study_random=optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "study_random.optimize(optuna_rf,n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизация optuna показывает отличное время если модель RandomForest. Время обучения составило чуть меньше минуты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(study_random.best_params) # Наилучшие значения гиперпараметров \n",
    "print(study_random.best_value) #\"f1_score на обучающем наборе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model_rf = RandomForestClassifier(**study_random.best_params,random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "print(\"accuracy на тестовом наборе: {:.3f}\".format(model_rf.score(X_test,y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test,y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study_random, target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=optimization_history_rf_Optuna.png width=1450px height=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По графику так же видим, что при увеличении итераций наша метрика растет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_ccccccccccc(study_random, target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=param_importances_Optuna_rf.png width=1450px height=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная зависимость от гиперпараметра max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study_random, params=[\"n_estimators\", \"max_depth\"],\n",
    "                                  target_name=\"f1_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=contour_Optuna_rf.png width=1450px height=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же на контурной карте видим, что максимальные значения достигаются при n_estimators=250 и max_depth=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Все модели имеют право на жизнь и на активное использование, т.к. достигают одиннаковые метрики. Вопрос только во временных рамках, но для удобства и с визуализацией отлично подойдет optuna. Так же она берет не те числа, которые мы сами вписываем или тот шаг, а рандомные, что может улучшить качество модели. Так же можно по визуализации понять, какие гиперпараметры модели более важные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=table.png width=1450px height=30%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
